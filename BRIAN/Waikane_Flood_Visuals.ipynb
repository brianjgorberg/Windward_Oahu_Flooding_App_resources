{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6954e7ce-a3b0-4e35-baa8-5b0537ffb371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from dateutil.tz import tzutc, tzlocal\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e177214-4f26-4d4c-8c8e-0cf4447a1365",
   "metadata": {},
   "source": [
    "# Pull Data from NOAA and USGS (stream height and tides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b99cc-0dc0-470c-a8be-6898d7508eb2",
   "metadata": {},
   "source": [
    "## Pull the last 24 hours of stream height data from Waikane USGS station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eac1dc-0914-4983-8e13-6e37d794a52b",
   "metadata": {},
   "source": [
    "This is the function for requesting USGS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f5cd8a-d5cb-41d3-87b7-c8293f7b33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def USGS_Data_Request(site, start_date, end_date, parameter):\n",
    "    \"\"\"\n",
    "    Download USGS instantaneous data from NWIS API.\n",
    "    Handles errors gracefully, converts to metric units, and adjusts for HST.\n",
    "    \"\"\"\n",
    "    \n",
    "    param_units = {\n",
    "        \"00045\": \"in\",       # Precipitation\n",
    "        \"00060\": \"ft3_s\",    # Discharge\n",
    "        \"00065\": \"ft\"        # Gage height\n",
    "    }\n",
    "\n",
    "    if parameter not in param_units:\n",
    "        raise ValueError(\"Unsupported parameter code. Use '00045', '00060', or '00065'.\")\n",
    "\n",
    "    unit_col = param_units[parameter]\n",
    "\n",
    "    url = (\n",
    "        f\"https://waterservices.usgs.gov/nwis/iv/?format=json\"\n",
    "        f\"&sites={site}&startDT={start_date}&endDT={end_date}\"\n",
    "        f\"&parameterCd={parameter}&siteStatus=all\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from USGS: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Handle case where no timeSeries are returned\n",
    "    if not data.get('value', {}).get('timeSeries'):\n",
    "        print(f\"No data available for site {site} and parameter {parameter}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Parse valid entries\n",
    "    rows = []\n",
    "    for ts in data['value']['timeSeries']:\n",
    "        for entry in ts['values'][0]['value']:\n",
    "            val_str = entry.get(\"value\", \"\")\n",
    "            try:\n",
    "                val = float(val_str)\n",
    "            except ValueError:\n",
    "                val = None\n",
    "\n",
    "            rows.append({\n",
    "                \"DateTime\": entry[\"dateTime\"],\n",
    "                unit_col: val\n",
    "            })\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime']).dt.tz_localize(None)\n",
    "    df = df[['DateTime', unit_col]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2325ed5-108f-4b1e-8509-beb1ed931306",
   "metadata": {},
   "source": [
    "Using the function, I will pull the last 24 hours of stream height data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efec9ed7-0210-48b0-997b-0c51aa04e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgorb\\AppData\\Local\\Temp\\ipykernel_44228\\3018553234.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  start_date = (datetime.utcnow() - timedelta(days=3)).strftime('%Y-%m-%dT%H:%M')\n",
      "C:\\Users\\bgorb\\AppData\\Local\\Temp\\ipykernel_44228\\3018553234.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end_date = datetime.utcnow().strftime('%Y-%m-%dT%H:%M')\n"
     ]
    }
   ],
   "source": [
    "#Waikane\n",
    "\n",
    "site = '16294900'\n",
    "parameter = \"00065\"\n",
    "\n",
    "# Set start and end dates in UTC with time included\n",
    "start_date = (datetime.utcnow() - timedelta(days=3)).strftime('%Y-%m-%dT%H:%M')\n",
    "end_date = datetime.utcnow().strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "df_16294900_H = USGS_Data_Request(site, start_date, end_date, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4064714-c52d-4989-a9f1-9bea1d6d0510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgorb\\AppData\\Local\\Temp\\ipykernel_44228\\2092448235.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  start_date = (datetime.utcnow() - timedelta(days=3)).strftime('%Y-%m-%dT%H:%M')\n",
      "C:\\Users\\bgorb\\AppData\\Local\\Temp\\ipykernel_44228\\2092448235.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end_date = datetime.utcnow().strftime('%Y-%m-%dT%H:%M')\n"
     ]
    }
   ],
   "source": [
    "#Waiahole\n",
    "\n",
    "site = '16294100'\n",
    "parameter = \"00065\"\n",
    "\n",
    "# Set start and end dates in UTC with time included\n",
    "start_date = (datetime.utcnow() - timedelta(days=3)).strftime('%Y-%m-%dT%H:%M')\n",
    "end_date = datetime.utcnow().strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "df_16294100_H = USGS_Data_Request(site, start_date, end_date, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c024d41b-6c4d-4669-8d91-bf5f1a0dad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max datetime: 2025-08-07 10:35:00\n",
      "24 hours earlier: 2025-08-06 10:35:00\n"
     ]
    }
   ],
   "source": [
    "# Ensure DateTime is sorted\n",
    "df_16294100_H = df_16294100_H.sort_values('DateTime').reset_index(drop=True)\n",
    "\n",
    "# Get the max datetime\n",
    "max_dt_16294100 = df_16294100_H['DateTime'].max()\n",
    "print(\"Max datetime:\", max_dt_16294100)\n",
    "\n",
    "# Compute the cutoff datetime (24 hours before max)\n",
    "cutoff_dt_16294100 = max_dt_16294100 - pd.Timedelta(hours=24)\n",
    "print(\"24 hours earlier:\", cutoff_dt_16294100)\n",
    "\n",
    "# Find the first row where datetime is greater than or equal to cutoff\n",
    "earlier_index_16294100 = df_16294100_H[df_16294100_H['DateTime'] >= cutoff_dt_16294100].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d25da3cb-e1ec-4379-bf87-02952188ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max datetime: 2025-08-07 10:25:00\n",
      "24 hours earlier: 2025-08-06 10:25:00\n"
     ]
    }
   ],
   "source": [
    "# Ensure DateTime is sorted\n",
    "df_16294900_H = df_16294900_H.sort_values('DateTime').reset_index(drop=True)\n",
    "\n",
    "# Get the max datetime\n",
    "max_dt_16294900 = df_16294900_H['DateTime'].max()\n",
    "print(\"Max datetime:\", max_dt_16294900)\n",
    "\n",
    "# Compute the cutoff datetime (24 hours before max)\n",
    "cutoff_dt_16294900 = max_dt_16294900 - pd.Timedelta(hours=24)\n",
    "print(\"24 hours earlier:\", cutoff_dt_16294900)\n",
    "\n",
    "# Find the first row where datetime is greater than or equal to cutoff\n",
    "earlier_index_16294900 = df_16294900_H[df_16294900_H['DateTime'] >= cutoff_dt_16294900].index[0]\n",
    "#print(\"Index at least 24 hours before max:\", earlier_index_16294900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee67b1-66bd-4834-a2d3-b786570013ed",
   "metadata": {},
   "source": [
    "## Pull the predicted tides for today from the nearest API NOAA station (Mokuoloe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66925e97-d8ec-4a1d-a3ac-e417e9936a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pull_NOAA_API(station_id, end_date, start_date, datum):\n",
    "    # Station and API settings\n",
    "    units = \"metric\"\n",
    "    time_zone = \"lst\"\n",
    "    clock = \"24hour\"\n",
    "    interval = \"hilo\"\n",
    "    product = \"predictions\"\n",
    "    output_file = station_id + \"_tide_predictions.csv\"\n",
    "    \n",
    "    # Time range: last 3 days\n",
    "\n",
    "    \n",
    "    # URL and parameters\n",
    "    base_url = \"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter\"\n",
    "    params = {\n",
    "        \"begin_date\": start_date.strftime(\"%Y%m%d\"),\n",
    "        \"end_date\": end_date.strftime(\"%Y%m%d\"),\n",
    "        \"station\": station_id,\n",
    "        \"product\": product,\n",
    "        \"datum\": datum,\n",
    "        \"units\": units,\n",
    "        \"time_zone\": time_zone,\n",
    "        \"clock\": clock,\n",
    "        \"interval\": interval,\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "    \n",
    "    # Download and save\n",
    "    print(f\"Downloading: {params['begin_date']} to {params['end_date']}\")\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        if \"No tide data was found\" in response.text:\n",
    "            print(\"❌ No tide data found for this range.\")\n",
    "        else:\n",
    "            df_tides = pd.read_csv(StringIO(response.text))\n",
    "            df_tides.to_csv(output_file, index=False)\n",
    "            print(f\"\\n✅ Tide data saved to {output_file} ({len(df_tides)} rows)\")\n",
    "    else:\n",
    "        print(f\"❌ Request failed (status code {response.status_code})\")\n",
    "        print(response.text)\n",
    "\n",
    "    return df_tides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f9f3656-6dd9-4b75-914f-cfb567fa6c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 20250804 to 20250809\n",
      "\n",
      "✅ Tide data saved to 1612480_tide_predictions.csv (19 rows)\n"
     ]
    }
   ],
   "source": [
    "# Time range: last 3 days\n",
    "end_date = datetime.today() + timedelta(days=2)\n",
    "start_date = end_date - timedelta(days=5)\n",
    "station_id = \"1612480\"\n",
    "\n",
    "df_Mokouloe = Pull_NOAA_API(station_id, end_date, start_date, datum = 'MLLW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff101f-bf33-44bc-b18a-676332380ed4",
   "metadata": {},
   "source": [
    "### Convert the predicted tides for Mokouloe to tides for Waikane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c2a2a94-a34a-446a-bd0a-d04c26a27cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_Mokouloe_to_Waikane(Source_df, HEIGHT_OFFSET_HIGH, HEIGHT_OFFSET_LOW, TIME_OFFSET_HIGH, TIME_OFFSET_LOW):\n",
    "    \"\"\"\n",
    "    Adjust tide predictions from Moku o Lo‘e to Waikāne using NOAA time and height offsets.\n",
    "    Converts predictions from meters to feet and renames column to 'Prediction_ft_MSL'.\n",
    "\n",
    "    Parameters:\n",
    "        Source_df (pd.DataFrame): Input tide prediction DataFrame with 'Date Time', 'Prediction', and 'Type'.\n",
    "        HEIGHT_OFFSET_HIGH (float): Height multiplier for high tides.\n",
    "        HEIGHT_OFFSET_LOW (float): Height multiplier for low tides.\n",
    "        TIME_OFFSET_HIGH (int): Time offset in minutes for high tides.\n",
    "        TIME_OFFSET_LOW (int): Time offset in minutes for low tides.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Adjusted DataFrame with feet predictions and updated column name.\n",
    "    \"\"\"\n",
    "\n",
    "    required = ['Date Time', 'Prediction', 'Type']\n",
    "    df = Source_df.copy()\n",
    "    df.columns = df.columns.str.strip()  # clean column names\n",
    "\n",
    "    if not all(col in df.columns for col in required):\n",
    "        raise ValueError(f\"Missing required columns. Found columns: {df.columns.tolist()}\")\n",
    "\n",
    "    df['Date Time'] = pd.to_datetime(df['Date Time'])\n",
    "\n",
    "    def apply_offsets(row):\n",
    "        if row['Type'] == 'H':\n",
    "            row['Date Time'] += pd.Timedelta(minutes=TIME_OFFSET_HIGH)\n",
    "            row['Prediction'] *= HEIGHT_OFFSET_HIGH\n",
    "        elif row['Type'] == 'L':\n",
    "            row['Date Time'] += pd.Timedelta(minutes=TIME_OFFSET_LOW)\n",
    "            row['Prediction'] *= HEIGHT_OFFSET_LOW\n",
    "        return row\n",
    "\n",
    "    # Apply NOAA time/height offsets\n",
    "    df = df.apply(apply_offsets, axis=1)\n",
    "\n",
    "    # Convert meters to feet and rename column\n",
    "    df['Prediction_ft_MSL'] = df['Prediction'] * 3.28084\n",
    "    return df[['Date Time', 'Prediction_ft_MSL', 'Type']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a48c13a9-fdc8-47c4-b536-9cc011354f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Waikane_HILO = convert_Mokouloe_to_Waikane(df_Mokouloe, HEIGHT_OFFSET_HIGH = 1.13, HEIGHT_OFFSET_LOW = 1, TIME_OFFSET_HIGH = -22, TIME_OFFSET_LOW = -4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961c7a5-f18c-410c-90b4-a88490eaa00e",
   "metadata": {},
   "source": [
    "# Calculate the Next Tide from the current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eccd1cbf-814d-49d9-b45e-6bb7f2e1e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-07 14:16:00 H 2.9 ft\n"
     ]
    }
   ],
   "source": [
    "df_Waikane_HILO[\"Date Time\"] = pd.to_datetime(df_Waikane_HILO[\"Date Time\"])\n",
    "\n",
    "# Your reference date\n",
    "ref_date = datetime.now() #current time\n",
    "next_row = df_Waikane_HILO[df_Waikane_HILO[\"Date Time\"] > ref_date].sort_values(\"Date Time\").reset_index(drop=True)\n",
    "\n",
    "# Clean column names\n",
    "next_tide_type = next_row[\"Type\"][0]\n",
    "next_tide_height = next_row[\"Prediction_ft_MSL\"][0]\n",
    "next_tide_time = next_row[\"Date Time\"][0]\n",
    "\n",
    "print(str(next_tide_time) + \" \" + next_tide_type + \" \" + str(round(next_tide_height, 2)) + \" ft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790ce17-5cf2-4093-89b3-d077f277f992",
   "metadata": {},
   "source": [
    "### Create a time series using the HIGH and LOW and convert to feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a4162b7-0704-4ee6-bb45-24dab2e0dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_HILO_to_5min_series(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert to datetime and round to nearest 5 min\n",
    "    df[\"Date Time\"] = pd.to_datetime(df[\"Date Time\"])\n",
    "    df[\"Date Time\"] = df[\"Date Time\"].dt.round(\"5min\")\n",
    "    df = df.sort_values(\"Date Time\").reset_index(drop=True)\n",
    "\n",
    "    # Function to generate sine interpolation between two tide points\n",
    "    def fit_sine_wave(t0, t1, y0, y1):\n",
    "        duration = (t1 - t0).total_seconds()\n",
    "        if duration <= 0:\n",
    "            return [], []\n",
    "\n",
    "        steps = int(duration / 300) + 1  # 5-minute intervals\n",
    "        times = [t0 + timedelta(seconds=i * 300) for i in range(steps)]\n",
    "        elapsed = np.array([(t - t0).total_seconds() for t in times])\n",
    "        omega = np.pi / duration  # 0 to pi for half-wave\n",
    "        amplitude = (y1 - y0) / 2\n",
    "        offset = (y1 + y0) / 2\n",
    "        levels = amplitude * np.sin(omega * elapsed - np.pi/2) + offset\n",
    "        return times, levels\n",
    "\n",
    "    # Build full 5-minute interpolated time series\n",
    "    full_times = []\n",
    "    full_levels = []\n",
    "\n",
    "    for i in range(len(df) - 1):\n",
    "        t0 = df.loc[i, \"Date Time\"]\n",
    "        t1 = df.loc[i + 1, \"Date Time\"]\n",
    "        y0 = df.loc[i, \"Prediction_ft_MSL\"]\n",
    "        y1 = df.loc[i + 1, \"Prediction_ft_MSL\"]\n",
    "        seg_times, seg_levels = fit_sine_wave(t0, t1, y0, y1)\n",
    "        full_times.extend(seg_times)\n",
    "        full_levels.extend(seg_levels)\n",
    "\n",
    "    # Final DataFrame\n",
    "    df_5min = pd.DataFrame({\n",
    "        \"Datetime\": full_times,\n",
    "        \"Predicted_ft_MSL\": [round(lvl, 2) for lvl in full_levels]\n",
    "    }).drop_duplicates(\"Datetime\").sort_values(\"Datetime\").reset_index(drop=True)\n",
    "\n",
    "    return df_5min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df8c3116-0cc1-4cd0-9ee1-127a80a2d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Waikane_5min = convert_HILO_to_5min_series(df_Waikane_HILO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88f2b9-43a0-4bd0-92ed-3f4a4b08f9fb",
   "metadata": {},
   "source": [
    "# FOR ANNE:  PLOT A GRAPH SHOWING NEXT DAY, TODAY AND PREVIOUS DAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee39e4-aa65-462a-9c5e-c3d7746ff10a",
   "metadata": {},
   "source": [
    "# Visualize the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51703f06-4ba1-452e-a3d4-82c2adf05018",
   "metadata": {},
   "source": [
    "## Pull in the flooding threshold values for stream and tide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "461209d1-c029-44f8-8d6a-8534861a5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative path to the folder\n",
    "folder_path = os.path.join('.', 'Flooding_Thresholds')\n",
    "\n",
    "# Define full file paths\n",
    "stream16294900_thresholds = os.path.join(folder_path, 'Waikane_16294900_stream_flood_thresholds.csv')\n",
    "stream16294100_thresholds = os.path.join(folder_path, 'Waiahole_16294100_stream_flood_thresholds.csv')\n",
    "\n",
    "tide_thresholds = os.path.join(folder_path, 'Mokuoloe-Waikane_tide_flood_thresholds.csv')\n",
    "\n",
    "# Read CSVs\n",
    "df_stream16294900_thresholds = pd.read_csv(stream16294900_thresholds)\n",
    "df_stream16294100_thresholds = pd.read_csv(stream16294100_thresholds)\n",
    "df_tide_thresholds = pd.read_csv(tide_thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f59dd9-1047-49e3-9b51-e72b50d857e3",
   "metadata": {},
   "source": [
    "# Rain Gauge Data Stuff (POTENTIAL FOR FLOODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26ba93fe-4d37-434e-8d1d-bc97058dd5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgorb\\AppData\\Local\\Temp\\ipykernel_44228\\270114968.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  start_date = (datetime.utcnow() - timedelta(days=1)).strftime('%Y-%m-%dT%H:%M')\n",
      "C:\\Users\\bgorb\\AppData\\Local\\Temp\\ipykernel_44228\\270114968.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end_date = datetime.utcnow().strftime('%Y-%m-%dT%H:%M')\n"
     ]
    }
   ],
   "source": [
    "#Waiahole Rain Gage\n",
    "site = '212855157504501'\n",
    "parameter = \"00045\"\n",
    "\n",
    "# Set start and end dates in UTC with time included\n",
    "start_date = (datetime.utcnow() - timedelta(days=1)).strftime('%Y-%m-%dT%H:%M')\n",
    "end_date = datetime.utcnow().strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "df_212855157504501_RF = USGS_Data_Request(site, start_date, end_date, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a41217f9-4d32-4eda-afcb-4d553020f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainfall in the last hour: 0.00 inches\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_threshold</th>\n",
       "      <th>Precipitation_in</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_year</td>\n",
       "      <td>2.8</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_year</td>\n",
       "      <td>4.1</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max</td>\n",
       "      <td>7.6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RF_threshold  Precipitation_in   color\n",
       "0          min               0.0   green\n",
       "1       2_year               2.8  yellow\n",
       "2      10_year               4.1     red\n",
       "3          max               7.6     red"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the latest timestamp in the DataFrame\n",
    "latest_time = df_212855157504501_RF[\"DateTime\"].max()\n",
    "# Define 1-hour window\n",
    "one_hour_ago = latest_time - timedelta(hours=1)\n",
    "# Filter for the last 1 hour of data\n",
    "last_hour_data = df_212855157504501_RF[\n",
    "    (df_212855157504501_RF[\"DateTime\"] > one_hour_ago) &\n",
    "    (df_212855157504501_RF[\"DateTime\"] <= latest_time)\n",
    "]\n",
    "# Compute the sum\n",
    "last_hour_sum = last_hour_data[\"in\"].sum()\n",
    "print(f\"Rainfall in the last hour: {last_hour_sum:.2f} inches\")\n",
    "\n",
    "Waiahole_RF_thresholds = os.path.join(folder_path, 'Rain_Gauge_Thresholds_Waiahole.csv')\n",
    "df_RF_thresholds = pd.read_csv(Waiahole_RF_thresholds)\n",
    "df_RF_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be76dbe-435b-4fb4-a9be-a9d9050b364d",
   "metadata": {},
   "source": [
    "# Determine if stream is rising or falling !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c997f29a-09c0-4119-810a-1ae50396b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_height_trend(stream_height_dataframe):\n",
    "\n",
    "    # Ensure datetime is parsed and data is sorted\n",
    "    stream_height_dataframe['DateTime'] = pd.to_datetime(stream_height_dataframe['DateTime'])\n",
    "    stream_height_dataframe = stream_height_dataframe.sort_values('DateTime')\n",
    "    \n",
    "    # Define the time of the latest reading\n",
    "    latest_time = stream_height_dataframe['DateTime'].max()\n",
    "    latest_ft = stream_height_dataframe.loc[stream_height_dataframe['DateTime'] == latest_time, 'ft'].values[0]\n",
    "    \n",
    "    # Define the target time (1 hour prior)\n",
    "    target_time = latest_time - pd.Timedelta(minutes=30)\n",
    "    \n",
    "    # Find the closest time BEFORE or NEAR the target (within ±10 minutes)\n",
    "    time_window = pd.Timedelta(minutes=10)\n",
    "    possible_matches = stream_height_dataframe[\n",
    "        (stream_height_dataframe['DateTime'] >= target_time - time_window) &\n",
    "        (stream_height_dataframe['DateTime'] <= target_time + time_window)\n",
    "    ]\n",
    "    \n",
    "    # Choose the row with the smallest time difference to the target\n",
    "    threshold_feet = 0.15 #this is the threshold incase the trend is relatively stable\n",
    "    \n",
    "    if not possible_matches.empty:\n",
    "        closest_idx = (possible_matches['DateTime'] - target_time).abs().idxmin()\n",
    "        prior_ft = stream_height_dataframe.loc[closest_idx, 'ft']\n",
    "        prior_time = stream_height_dataframe.loc[closest_idx, 'DateTime']\n",
    "    \n",
    "        # Compare with threshold\n",
    "        diff = latest_ft - prior_ft\n",
    "        if abs(diff) <= threshold_feet:\n",
    "            trend = \"Stable\"\n",
    "        elif diff > 0:\n",
    "            trend = \"Rising\"\n",
    "        else:\n",
    "            trend = \"Falling\"\n",
    "    \n",
    "    else:\n",
    "        trend = \"Undetermined\"\n",
    "        print(\"Lack of readings, trend undetermined.\")\n",
    "\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5180db2f-ebe6-44c5-9e17-0f3aec05ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Waikane_trend = get_stream_height_trend(stream_height_dataframe = df_16294900_H)\n",
    "Waiahole_trend = get_stream_height_trend(stream_height_dataframe = df_16294100_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74063f7-c3c2-4d81-aa6c-ba50fad8df58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
